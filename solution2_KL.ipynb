{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbdbfbe7",
   "metadata": {},
   "source": [
    "# Exercise 2: Tracking-by-detection with an integer linear program (ILP)\n",
    "\n",
    "You could also run this notebook on your laptop, a GPU is not needed :).\n",
    "\n",
    "<center><img src=\"figures/ilp_nodiv.png\" width=\"900\"/></center>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "Set your python kernel to <code>08-ilp-tracking</code>\n",
    "</div>\n",
    "\n",
    "You will learn\n",
    "- how linking with global context can be modeled and solved efficiently as a **network flow** using `motile` ([docs here](https://funkelab.github.io/motile/)) for a small-scale problem (Exercise 2.1).\n",
    "- to adapt the previous formulation to allow for **arbitrary track starting and ending points** (Exercise 2.2).\n",
    "- to extend the ILP to properly model **cell divisions** (Exercise 2.3).\n",
    "- to tune the **hyperparameters** of the ILP (Exercise 2.4, bonus).\n",
    "\n",
    "\n",
    "Places where you are expected to write code are marked with\n",
    "```\n",
    "######################\n",
    "### YOUR CODE HERE ###\n",
    "######################\n",
    "```\n",
    "\n",
    "This notebook was originally written by Benjamin Gallusser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc14f2",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d98b399-0bce-4a05-b684-ba1f65f4bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e486fafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Notebook at full width in the browser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import napari\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"iframe\"\n",
    "\n",
    "import motile\n",
    "from motile.plot import draw_track_graph, draw_solution\n",
    "from utils import InOutSymmetry, MinTrackLength\n",
    "\n",
    "import traccuracy\n",
    "from traccuracy import run_metrics\n",
    "from traccuracy.matchers import CTCMatched\n",
    "from traccuracy.metrics import CTCMetrics, DivisionMetrics\n",
    "from KL_load_data import load_raw_masks\n",
    "\n",
    "# Pretty tqdm progress bars\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badfef20",
   "metadata": {},
   "source": [
    "## Load the dataset and inspect it in napari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4dc5a",
   "metadata": {},
   "source": [
    "For this exercise we will work with a small excerpt of the dataset from exercise 1. We already provide you with the detections this time, let's load them and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "320678bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared_data/YeastiBois/baby_data/Fig1_brightfield_and_seg_outputs/imgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [00:00, 396.99it/s]\n",
      "300it [00:00, 412.52it/s]\n"
     ]
    }
   ],
   "source": [
    "base_path = Path(\n",
    "    \"/mnt/efs/shared_data/YeastiBois/baby_data/Fig1_brightfield_and_seg_outputs\")\n",
    "# data = np.load(base_path / \"detected_renumbered.npz\", allow_pickle=True)\n",
    "\n",
    "img, labels = load_raw_masks(base_path)\n",
    "img = np.stack(img)\n",
    "labels = np.stack(labels)\n",
    "# links = pd.DataFrame(data[\"links\"], columns=[\n",
    "#                     \"track_id\", \"from\", \"to\", \"parent_id\"])\n",
    "# det = data[\"det\"]\n",
    "# det_center_probs is a dictionary\n",
    "# det_center_probs = data[\"det_center_probs\"][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff510bd5",
   "metadata": {},
   "source": [
    "According to the `links` table, there should be two cell divisions in this video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc1a01ec",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 5, 117, 117) (300, 5, 117, 117)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape,\n",
    "      labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485c8e2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><h3>Napari in a jupyter notebook:</h3>\n",
    "\n",
    "- To have napari working in a jupyter notebook, you need to use up-to-date versions of napari, pyqt and pyqt5, as is the case in the conda environments provided together with this exercise.\n",
    "- When you are coding and debugging, close the napari viewer with `viewer.close()` to avoid problems with the two event loops of napari and jupyter.\n",
    "- **If a cell is not executed (empty square brackets on the left of a cell) despite you running it, running it a second time right after will usually work.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48021da9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Here's a little convenience function to visualize the ground truth tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf9bafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tracks(viewer, y, links=None, name=\"\"):\n",
    "    \"\"\"Utility function to visualize segmentation and tracks\n",
    "\n",
    "    Args:\n",
    "        viewer: napari viewer\n",
    "        y: labels: list of 2D arrays, each array is a label image.\n",
    "        links: np.ndarray, each row is a link (parent, child, parent_frame, child_frame).\n",
    "\n",
    "    Returns:\n",
    "        tracks: np.ndarray, shape (N, 4)\n",
    "    \"\"\"\n",
    "    max_label = max(links.max(), y.max()) if links is not None else y.max()\n",
    "    colorperm = np.random.default_rng(42).permutation(np.arange(1, max_label + 2))\n",
    "    tracks = []\n",
    "    for t, frame in enumerate(y):\n",
    "        centers = skimage.measure.regionprops(frame)\n",
    "        for c in centers:\n",
    "            tracks.append(\n",
    "                [colorperm[c.label], t, int(c.centroid[0]), int(c.centroid[1])]\n",
    "            )\n",
    "    tracks = np.array(tracks)\n",
    "    tracks = tracks[tracks[:, 0].argsort()]\n",
    "\n",
    "    graph = {}\n",
    "    if links is not None:\n",
    "        divisions = links[links[:, 3] != 0]\n",
    "        for d in divisions:\n",
    "            if (\n",
    "                colorperm[d[0]] not in tracks[:, 0]\n",
    "                or colorperm[d[3]] not in tracks[:, 0]\n",
    "            ):\n",
    "                continue\n",
    "            graph[colorperm[d[0]]] = [colorperm[d[3]]]\n",
    "\n",
    "    viewer.add_labels(y, name=f\"{name}_detections\")\n",
    "    # viewer.layers[f\"{name}_detections\"].contour = 3\n",
    "    viewer.add_tracks(tracks, name=f\"{name}_tracks\", graph=graph)\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e94dcd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewer = napari.viewer.current_viewer()\n",
    "# if viewer:\n",
    "#     viewer.close()\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(img)\n",
    "# #visualize_tracks(viewer, labels, links.to_numpy(), \"ground_truth\")\n",
    "# visualize_tracks(viewer, labels)\n",
    "# #viewer.add_labels(det, name=\"detections\")\n",
    "# #viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "314ee1d4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# viewer = napari.viewer.current_viewer()\n",
    "# if viewer:\n",
    "#     viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a72f087",
   "metadata": {},
   "source": [
    "## Build the ground truth graph, as well as a candidate graph from the detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1112ae2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "We will represent a linking problem as a [directed graph](https://en.wikipedia.org/wiki/Directed_graph) that contains all possible detections (graph nodes) and links (graph edges) between them.\n",
    "\n",
    "Then we remove certain nodes and edges using discrete optimization techniques such as an integer linear program (ILP).\n",
    "\n",
    "First of all, we will build and inspect two graphs:\n",
    "- One for the ground truth data.\n",
    "- A candidate graph built from the detected cells in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45aead91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gt_graph(labels, links=None):\n",
    "    \"\"\"Build a ground truth graph from a list of labels and links.\n",
    "\n",
    "    Args:\n",
    "        labels: list of 2D arrays, each array is a label image\n",
    "        links: np.ndarray, each row is a link (parent, child, parent_frame, child_frame).\n",
    "    Returns:\n",
    "        trackgraph: motile.TrackGraph containing the ground truth graph.\n",
    "        G: networkx.DiGraph containing the ground truth graph.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Build ground truth graph\")\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    luts = []\n",
    "    n_v = 0\n",
    "    for t, d in enumerate(labels):\n",
    "        lut = {}\n",
    "        regions = skimage.measure.regionprops(d)\n",
    "        positions = []\n",
    "        for i, r in enumerate(regions):\n",
    "            draw_pos = int(d.shape[0] - r.centroid[0])\n",
    "            if draw_pos in positions:\n",
    "                draw_pos += 3  # To avoid overlapping nodes\n",
    "            positions.append(draw_pos)\n",
    "            G.add_node(\n",
    "                n_v,\n",
    "                time=t,\n",
    "                show=r.label,\n",
    "                draw_position=draw_pos,\n",
    "                y=int(r.centroid[0]),\n",
    "                x=int(r.centroid[1]),\n",
    "            )\n",
    "            lut[r.label] = n_v\n",
    "            n_v += 1\n",
    "        luts.append(lut)\n",
    "\n",
    "    n_e = 0\n",
    "    for t, (d0, d1) in enumerate(zip(labels, labels[1:])):\n",
    "        r0 = skimage.measure.regionprops(d0)\n",
    "        c0 = [np.array(r.centroid) for r in r0]\n",
    "\n",
    "        r1 = skimage.measure.regionprops(d1)\n",
    "        c1 = [np.array(r.centroid) for r in r1]\n",
    "\n",
    "        for _r0, _c0 in zip(r0, c0):\n",
    "            for _r1, _c1 in zip(r1, c1):\n",
    "                dist = np.linalg.norm(_c0 - _c1)\n",
    "                if _r0.label == _r1.label:\n",
    "                    G.add_edge(\n",
    "                        luts[t][_r0.label],\n",
    "                        luts[t + 1][_r1.label],\n",
    "                        edge_id=n_e,\n",
    "                        is_intertrack_edge=0,\n",
    "                    )\n",
    "                    n_e += 1\n",
    "\n",
    "    if links is not None:\n",
    "        divisions = links[links[:, 3] != 0]\n",
    "        for d in divisions:\n",
    "            if d[1] > 0 and d[1] < labels.shape[0]:\n",
    "                try:\n",
    "                    G.add_edge(\n",
    "                        luts[d[1] - 1][d[3]],\n",
    "                        luts[d[1]][d[0]],\n",
    "                        edge_id=n_e,\n",
    "                        show=\"DIV\",\n",
    "                        is_intertrack_edge=1,\n",
    "                    )\n",
    "                    n_e += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "    trackgraph = motile.TrackGraph(G, frame_attribute=\"time\")\n",
    "\n",
    "    return trackgraph, G\n",
    "\n",
    "\n",
    "def build_graph(detections, max_distance, detection_probs=None, drift=(0, 0)):\n",
    "    \"\"\"Build a candidate graph from a list of detections.\n",
    "\n",
    "     Args:\n",
    "        detections: list of 2D arrays, each array is a label image.\n",
    "            Labels are expected to be consecutive integers starting from 1, background is 0.\n",
    "        max distance: maximum distance between centroids of two detections to place a candidate edge.\n",
    "        detection_probs: list of arrays, corresponding to ordered ids in detections.\n",
    "        drift: (y, x) tuple for drift correction in euclidian distance feature.\n",
    "    Returns:\n",
    "        G: motile.TrackGraph containing the candidate graph.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Build candidate graph\")\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for t, d in enumerate(detections):\n",
    "        regions = skimage.measure.regionprops(d)\n",
    "        positions = []\n",
    "        for i, r in enumerate(regions):\n",
    "            draw_pos = int(r.centroid[1])\n",
    "            if draw_pos in positions:\n",
    "                draw_pos += 3  # To avoid overlapping nodes\n",
    "            positions.append(draw_pos)\n",
    "            feature = (\n",
    "                np.round(detection_probs[r.label-1], decimals=2).item()\n",
    "                if detection_probs is not None\n",
    "                else 1\n",
    "            )\n",
    "            G.add_node(\n",
    "                r.label-1,\n",
    "                time=t,\n",
    "                show=r.label,\n",
    "                feature=feature,\n",
    "                draw_position=draw_pos,\n",
    "                z=int(r.centroid[0]),\n",
    "                y=int(r.centroid[1]),\n",
    "                x=int(r.centroid[2]),\n",
    "            )\n",
    "\n",
    "    n_e = 0\n",
    "    for t, (d0, d1) in enumerate(zip(detections, detections[1:])):\n",
    "        r0 = skimage.measure.regionprops(d0)\n",
    "        c0 = [np.array(r.centroid) for r in r0]\n",
    "\n",
    "        r1 = skimage.measure.regionprops(d1)\n",
    "        c1 = [np.array(r.centroid) for r in r1]\n",
    "\n",
    "        for _r0, _c0 in zip(r0, c0):\n",
    "            for _r1, _c1 in zip(r1, c1):\n",
    "                dist = np.linalg.norm(_c0 + np.array(drift) - _c1)\n",
    "                if dist < max_distance:\n",
    "                    G.add_edge(\n",
    "                        _r0.label - 1,\n",
    "                        _r1.label - 1,\n",
    "                        # 1 - normalized euclidian distance\n",
    "                        feature=1\n",
    "                        - np.round(\n",
    "                            np.linalg.norm(_c0 + np.array(drift) - _c1) / max_distance,\n",
    "                            decimals=3,\n",
    "                        ).item(),\n",
    "                        edge_id=n_e,\n",
    "                        show=\"?\",\n",
    "                    )\n",
    "                    n_e += 1\n",
    "\n",
    "    G = motile.TrackGraph(G, frame_attribute=\"time\")\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "791141cc-b95a-4111-ba0f-46e0672c7923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 300/300 [00:00<00:00, 9436.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for frame in labels:\n",
    "    vals = np.unique(frame)\n",
    "    assert vals.max() == len(vals) - 1\n",
    "\n",
    "n_v = 0\n",
    "relabeled = []\n",
    "for frame in tqdm(labels):\n",
    "    frame[frame != 0] += n_v\n",
    "    n_v = frame.max()\n",
    "    relabeled.append(frame)\n",
    "labels_global = np.stack(relabeled)\n",
    "print(n_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c900101-e91c-4cbc-b0eb-4fa3a265306e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1526"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_global.shape\n",
    "labels_global.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa543ca0-0bfd-4ed2-a152-1126bd57a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 300/300 [00:18<00:00, 15.83it/s]\n"
     ]
    }
   ],
   "source": [
    "det_probs = []\n",
    "for frame in tqdm(labels_global):\n",
    "    regions = skimage.measure.regionprops(frame)\n",
    "    for r in regions:\n",
    "        det_probs.append(r.solidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fffc7244-22ad-49e2-9598-cfa87b78f5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1526"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(det_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b95e042-58fd-4c03-8bfe-2657c1fe2d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build candidate graph\n"
     ]
    }
   ],
   "source": [
    "s = slice(0,300)\n",
    "labels_crop = labels[s]\n",
    "img_crop = img[s]\n",
    "candidate_graph = build_graph(labels_crop, max_distance=30, detection_probs=det_probs, drift=(0,0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0e691",
   "metadata": {},
   "source": [
    "Let's visualize the two graphs.\n",
    "\n",
    "In the ground truth graph nodes that belong to the same linear tracklet are marked with the same id. The two divisions in the dataset are marked in yellow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a920922",
   "metadata": {},
   "source": [
    "You can hover over the nodes and edges of the candidate graph to inspect their features.\n",
    "\n",
    "In contrast to the ground truth graph above, in the candidate graph, nodes have unique IDs.\n",
    "\n",
    "The nodes' `feature` is set to their detection probability, and the edges' `feature` to 1 - normalized_detection_distance, which is also visualized as their color saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8476ce86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# fig_candidate = draw_track_graph(\n",
    "#     candidate_graph,\n",
    "#     position_attribute=\"draw_position\",\n",
    "#     width=1000,\n",
    "#     height=500,\n",
    "#     label_attribute=\"show\",\n",
    "#     alpha_attribute=\"feature\",\n",
    "#     node_size=25,\n",
    "# )\n",
    "# fig_candidate = fig_candidate.update_layout(\n",
    "#     title={\n",
    "#         \"text\": \"Candidate graph\",\n",
    "#         \"y\": 0.98,\n",
    "#         \"x\": 0.5,\n",
    "#     }\n",
    "# )\n",
    "# fig_candidate.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f4b9cc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Here is a utility function to gauge some statistics of a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa00bff4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def print_solution_stats(solver, graph, gt_graph=None):\n",
    "    \"\"\"Prints the number of nodes and edges for candidate, ground truth graph, and solution graph.\n",
    "\n",
    "    Args:\n",
    "        solver: motile.Solver, after calling solver.solve()\n",
    "        graph: motile.TrackGraph, candidate graph\n",
    "        gt_graph: motile.TrackGraph, ground truth graph\n",
    "    \"\"\"\n",
    "    time.sleep(0.1)  # to wait for ilpy prints\n",
    "    print(\n",
    "        f\"\\nCandidate graph\\t\\t{len(graph.nodes):3} nodes\\t{len(graph.edges):3} edges\"\n",
    "    )\n",
    "    if gt_graph:\n",
    "        print(\n",
    "            f\"Ground truth graph\\t{len(gt_graph.nodes):3} nodes\\t{len(gt_graph.edges):3} edges\"\n",
    "        )\n",
    "\n",
    "    node_selected = solver.get_variables(motile.variables.NodeSelected)\n",
    "    edge_selected = solver.get_variables(motile.variables.EdgeSelected)\n",
    "    nodes = 0\n",
    "    for node in candidate_graph.nodes:\n",
    "        if solver.solution[node_selected[node]] > 0.5:\n",
    "            nodes += 1\n",
    "    edges = 0\n",
    "    for u, v in candidate_graph.edges:\n",
    "        if solver.solution[edge_selected[(u, v)]] > 0.5:\n",
    "            edges += 1\n",
    "    print(f\"Solution graph\\t\\t{nodes:3} nodes\\t{edges:3} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1949216",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Recolor detections in napari according to solution and compare to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "426b395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution2graph(solver, base_graph, detections, label_key=\"show\"):\n",
    "    \"\"\"Convert a solver solution to a graph and corresponding dense selected detections.\n",
    "\n",
    "    Args:\n",
    "        solver: A solver instance\n",
    "        base_graph: The base graph\n",
    "        detections: The detections\n",
    "        label_key: The key of the label in the detections\n",
    "    Returns:\n",
    "        track_graph: Solution as motile.TrackGraph\n",
    "        graph: Solution as networkx graph\n",
    "        selected_detections: Dense label array containing only selected detections\n",
    "    \"\"\"\n",
    "    graph = nx.DiGraph()\n",
    "    node_indicators = solver.get_variables(motile.variables.NodeSelected)\n",
    "    edge_indicators = solver.get_variables(motile.variables.EdgeSelected)\n",
    "\n",
    "    selected_detections = np.zeros_like(detections)\n",
    "\n",
    "    # Build nodes\n",
    "    for node, index in node_indicators.items():\n",
    "        if solver.solution[index] > 0.5:\n",
    "            node_features = base_graph.nodes[node]\n",
    "            graph.add_node(node, **node_features)\n",
    "            t = node_features[base_graph.frame_attribute]\n",
    "            selected_detections[t][\n",
    "                detections[t] == node_features[label_key]\n",
    "            ] = node_features[label_key]\n",
    "\n",
    "    # Build edges\n",
    "    for edge, index in edge_indicators.items():\n",
    "        if solver.solution[index] > 0.5:\n",
    "            # print(base_graph.edges[edge])\n",
    "            graph.add_edge(*edge, **base_graph.edges[edge])\n",
    "\n",
    "    # Add cell division markers on edges for traccuracy\n",
    "    for (u, v), features in graph.edges.items():\n",
    "        out_edges = graph.out_edges(u)\n",
    "        if len(out_edges) == 2:\n",
    "            features[\"is_intertrack_edge\"] = 1\n",
    "        elif len(out_edges) == 1:\n",
    "            features[\"is_intertrack_edge\"] = 0\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "    track_graph = motile.TrackGraph(graph, frame_attribute=\"time\")\n",
    "\n",
    "    return track_graph, graph, selected_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49b18a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recolor_segmentation(segmentation, graph, det_attribute=\"show\"):\n",
    "    \"\"\"Recolor a segmentation based on a graph, such that each cell and its daughter cells have a unique color.\n",
    "\n",
    "    Args:\n",
    "        segmentation (np.ndarray): Predicted dense segmentation.\n",
    "        graph (motile.TrackGraph): A directed graph representing the tracks.\n",
    "        det_attribute (str): The attribute of the graph nodes that corresponds to ids in `segmentation`.\n",
    "\n",
    "    Returns:\n",
    "        out (np.ndarray): A recolored segmentation.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    n_tracks = 1\n",
    "    color_lookup_tables = []\n",
    "\n",
    "    for t in range(0, len(segmentation)):\n",
    "        new_frame = np.zeros_like(segmentation[t])\n",
    "        color_lut = {}\n",
    "        for node_id in graph.nodes_by_frame(t):\n",
    "            det_id = graph.nodes[node_id][det_attribute]\n",
    "            if node_id not in graph.nodes:\n",
    "                continue\n",
    "\n",
    "            in_edges = []\n",
    "            for u, v in graph.edges:\n",
    "                if v == node_id:\n",
    "                    in_edges.append((u, v))\n",
    "            if not in_edges:\n",
    "                new_frame[segmentation[t] == det_id] = n_tracks\n",
    "                color_lut[det_id] = n_tracks\n",
    "                n_tracks += 1\n",
    "            else:\n",
    "                for v_tm1, u_t0 in in_edges:\n",
    "                    new_frame[\n",
    "                        segmentation[t] == graph.nodes[u_t0][det_attribute]\n",
    "                    ] = color_lookup_tables[t - 1][graph.nodes[v_tm1][det_attribute]]\n",
    "                    color_lut[graph.nodes[u_t0][det_attribute]] = color_lookup_tables[\n",
    "                        t - 1\n",
    "                    ][graph.nodes[v_tm1][det_attribute]]\n",
    "\n",
    "        color_lookup_tables.append(color_lut)\n",
    "        out.append(new_frame)\n",
    "\n",
    "    out = np.stack(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85057b4",
   "metadata": {},
   "source": [
    "## Exercise 2.2 - ILP with track birth and death\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.2: Adapt the network flow from Exercise 2.1 such that tracks can start and end at arbitrary time points.</h3>\n",
    "\n",
    "Hint: You will have to add both costs and constraints to the template below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5cca7f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Expected output:\n",
    "\n",
    "<img src=\"figures/ilp_nodiv.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8de2a05",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def solve(graph):\n",
    "    \"\"\"ILP allowing for appearance and disappearance of cells.\n",
    "\n",
    "    Args:\n",
    "        graph (motile.TrackGraph): The candidate graph.\n",
    "\n",
    "    Returns:\n",
    "        solver (motile.Solver): The solver.\n",
    "    \"\"\"\n",
    "\n",
    "    solver = motile.Solver(graph)\n",
    "\n",
    "    solver.add_costs(\n",
    "        motile.costs.NodeSelection(\n",
    "            weight=-1,\n",
    "            attribute=\"feature\",\n",
    "            constant=0,\n",
    "        )\n",
    "    )\n",
    "    # weight * attribute + constant\n",
    "    solver.add_costs(\n",
    "        motile.costs.EdgeSelection(\n",
    "            weight=-1,\n",
    "            attribute=\"feature\",\n",
    "            constant=0,\n",
    "        )\n",
    "    )\n",
    "    solver.add_costs(motile.costs.Appear(constant=1))\n",
    "    solver.add_costs(motile.costs.Split(constant=1))\n",
    "    solver.add_costs(motile.costs.Disappear(constant=8))\n",
    "    \n",
    "    solver.add_constraints(motile.constraints.MaxParents(1))\n",
    "    solver.add_constraints(motile.constraints.MaxChildren(2))\n",
    "\n",
    "    solution = solver.solve()\n",
    "\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccb104",
   "metadata": {},
   "source": [
    "Run the optimization, and compare the found solution to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35910cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not create Gurobi backend: Gurobi error in ilpy/impl/solvers/GurobiBackend.cpp:22: PIP license can only be used from gurobipy interface\n",
      "\n",
      "Candidate graph\t\t1526 nodes\t4888 edges\n",
      "Solution graph\t\t1405 nodes\t1400 edges\n"
     ]
    }
   ],
   "source": [
    "with_birth = solve(candidate_graph)\n",
    "print_solution_stats(with_birth, candidate_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1924ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_birth = draw_solution(\n",
    "#     candidate_graph,\n",
    "#     with_birth,\n",
    "#     position_attribute=\"draw_position\",\n",
    "#     width=1000,\n",
    "#     height=500,\n",
    "#     label_attribute=\"show\",\n",
    "#     node_size=25,\n",
    "# )\n",
    "# fig_birth = fig_birth.update_layout(\n",
    "#     title={\n",
    "#         \"text\": f\"ILP formulation (no divisions) - cost: {with_birth.solution.get_value()}\",\n",
    "#         \"y\": 0.98,\n",
    "#         \"x\": 0.5,\n",
    "#     }\n",
    "# )\n",
    "# fig_birth.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48f07094",
   "metadata": {},
   "outputs": [],
   "source": [
    "recolored_birth = recolor_segmentation(\n",
    "    labels_crop, graph=solution2graph(with_birth, candidate_graph, labels_crop)[0]\n",
    ")\n",
    "\n",
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img_crop)\n",
    "viewer.add_labels(labels_crop)\n",
    "# visualize_track\n",
    "visualize_tracks(viewer, recolored_birth)\n",
    "\n",
    "viewer.add_labels(recolored_birth)\n",
    "viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98415dd0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, birth_graph, birth_det = solution2graph(with_birth, candidate_graph, det)\n",
    "get_metrics(gt_nx_graph, labels, birth_graph, birth_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02019057",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ilp_graph, ilp_det = solution2graph(full_ilp, candidate_graph, det)\n",
    "get_metrics(gt_nx_graph, labels, ilp_graph, ilp_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dcd6da",
   "metadata": {},
   "source": [
    "## Exercise 2.4 (Bonus)\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.4: Try to improve the ILP-based tracking from exercise 2.3</h3>\n",
    "\n",
    "For example\n",
    "- Tune the hyperparameters.\n",
    "- Better edge features than drift-corrected euclidian distance.\n",
    "- Tune the detection algorithm to avoid false negatives.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "formats": "py:percent,ipynb"
  },
  "kernelspec": {
   "display_name": "Python [conda env:08-ilp-tracking]",
   "language": "python",
   "name": "conda-env-08-ilp-tracking-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
