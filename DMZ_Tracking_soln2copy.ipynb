{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbdbfbe7",
   "metadata": {},
   "source": [
    "# Exercise 2: Tracking-by-detection with an integer linear program (ILP)\n",
    "\n",
    "You could also run this notebook on your laptop, a GPU is not needed :).\n",
    "\n",
    "<center><img src=\"figures/ilp_nodiv.png\" width=\"900\"/></center>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "Set your python kernel to <code>08-ilp-tracking</code>\n",
    "</div>\n",
    "\n",
    "You will learn\n",
    "- how linking with global context can be modeled and solved efficiently as a **network flow** using `motile` ([docs here](https://funkelab.github.io/motile/)) for a small-scale problem (Exercise 2.1).\n",
    "- to adapt the previous formulation to allow for **arbitrary track starting and ending points** (Exercise 2.2).\n",
    "- to extend the ILP to properly model **cell divisions** (Exercise 2.3).\n",
    "- to tune the **hyperparameters** of the ILP (Exercise 2.4, bonus).\n",
    "\n",
    "\n",
    "Places where you are expected to write code are marked with\n",
    "```\n",
    "######################\n",
    "### YOUR CODE HERE ###\n",
    "######################\n",
    "```\n",
    "\n",
    "This notebook was originally written by Benjamin Gallusser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc14f2",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook at full width in the browser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import napari\n",
    "import networkx as nx\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"iframe\"\n",
    "\n",
    "import motile\n",
    "from motile.plot import draw_track_graph, draw_solution\n",
    "from utils import InOutSymmetry, MinTrackLength\n",
    "\n",
    "import traccuracy\n",
    "from traccuracy import run_metrics\n",
    "from traccuracy.matchers import CTCMatched\n",
    "from traccuracy.metrics import CTCMetrics, DivisionMetrics\n",
    "\n",
    "# Pretty tqdm progress bars\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badfef20",
   "metadata": {},
   "source": [
    "## Load the dataset and inspect it in napari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4dc5a",
   "metadata": {},
   "source": [
    "For this exercise we will work with a small excerpt of the dataset from exercise 1. We already provide you with the detections this time, let's load them and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320678bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"data/exercise2\")\n",
    "data = np.load(base_path / \"detected_renumbered.npz\", allow_pickle=True)\n",
    "img = data[\"img\"]\n",
    "labels = data[\"labels\"]\n",
    "links = pd.DataFrame(data[\"links\"], columns=[\"track_id\", \"from\", \"to\", \"parent_id\"])\n",
    "det = data[\"det\"]\n",
    "det_center_probs = data[\"det_center_probs\"][()]  # det_center_probs is a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff510bd5",
   "metadata": {},
   "source": [
    "According to the `links` table, there should be two cell divisions in this video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a01ec",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485c8e2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><h3>Napari in a jupyter notebook:</h3>\n",
    "\n",
    "- To have napari working in a jupyter notebook, you need to use up-to-date versions of napari, pyqt and pyqt5, as is the case in the conda environments provided together with this exercise.\n",
    "- When you are coding and debugging, close the napari viewer with `viewer.close()` to avoid problems with the two event loops of napari and jupyter.\n",
    "- **If a cell is not executed (empty square brackets on the left of a cell) despite you running it, running it a second time right after will usually work.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48021da9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Here's a little convenience function to visualize the ground truth tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9bafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tracks(viewer, y, links=None, name=\"\"):\n",
    "    \"\"\"Utility function to visualize segmentation and tracks\n",
    "\n",
    "    Args:\n",
    "        viewer: napari viewer\n",
    "        y: labels: list of 2D arrays, each array is a label image.\n",
    "        links: np.ndarray, each row is a link (parent, child, parent_frame, child_frame).\n",
    "\n",
    "    Returns:\n",
    "        tracks: np.ndarray, shape (N, 4)\n",
    "    \"\"\"\n",
    "    max_label = max(links.max(), y.max()) if links is not None else y.max()\n",
    "    colorperm = np.random.default_rng(42).permutation(np.arange(1, max_label + 2))\n",
    "    tracks = []\n",
    "    for t, frame in enumerate(y):\n",
    "        centers = skimage.measure.regionprops(frame)\n",
    "        for c in centers:\n",
    "            tracks.append(\n",
    "                [colorperm[c.label], t, int(c.centroid[0]), int(c.centroid[1])]\n",
    "            )\n",
    "    tracks = np.array(tracks)\n",
    "    tracks = tracks[tracks[:, 0].argsort()]\n",
    "\n",
    "    graph = {}\n",
    "    if links is not None:\n",
    "        divisions = links[links[:, 3] != 0]\n",
    "        for d in divisions:\n",
    "            if (\n",
    "                colorperm[d[0]] not in tracks[:, 0]\n",
    "                or colorperm[d[3]] not in tracks[:, 0]\n",
    "            ):\n",
    "                continue\n",
    "            graph[colorperm[d[0]]] = [colorperm[d[3]]]\n",
    "\n",
    "    viewer.add_labels(y, name=f\"{name}_detections\")\n",
    "    viewer.layers[f\"{name}_detections\"].contour = 3\n",
    "    viewer.add_tracks(tracks, name=f\"{name}_tracks\", graph=graph)\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94dcd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img)\n",
    "visualize_tracks(viewer, labels, links.to_numpy(), \"ground_truth\")\n",
    "viewer.add_labels(det, name=\"detections\")\n",
    "viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ee1d4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a72f087",
   "metadata": {},
   "source": [
    "## Build the ground truth graph, as well as a candidate graph from the detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1112ae2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "We will represent a linking problem as a [directed graph](https://en.wikipedia.org/wiki/Directed_graph) that contains all possible detections (graph nodes) and links (graph edges) between them.\n",
    "\n",
    "Then we remove certain nodes and edges using discrete optimization techniques such as an integer linear program (ILP).\n",
    "\n",
    "First of all, we will build and inspect two graphs:\n",
    "- One for the ground truth data.\n",
    "- A candidate graph built from the detected cells in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aead91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gt_graph(labels, links=None):\n",
    "    \"\"\"Build a ground truth graph from a list of labels and links.\n",
    "\n",
    "    Args:\n",
    "        labels: list of 2D arrays, each array is a label image\n",
    "        links: np.ndarray, each row is a link (parent, child, parent_frame, child_frame).\n",
    "    Returns:\n",
    "        trackgraph: motile.TrackGraph containing the ground truth graph.\n",
    "        G: networkx.DiGraph containing the ground truth graph.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Build ground truth graph\")\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    luts = []\n",
    "    n_v = 0\n",
    "    for t, d in enumerate(labels):\n",
    "        lut = {}\n",
    "        regions = skimage.measure.regionprops(d)\n",
    "        positions = []\n",
    "        for i, r in enumerate(regions):\n",
    "            draw_pos = int(d.shape[0] - r.centroid[0])\n",
    "            if draw_pos in positions:\n",
    "                draw_pos += 3  # To avoid overlapping nodes\n",
    "            positions.append(draw_pos)\n",
    "            G.add_node(\n",
    "                n_v,\n",
    "                time=t,\n",
    "                show=r.label,\n",
    "                draw_position=draw_pos,\n",
    "                y=int(r.centroid[0]),\n",
    "                x=int(r.centroid[1]),\n",
    "            )\n",
    "            lut[r.label] = n_v\n",
    "            n_v += 1\n",
    "        luts.append(lut)\n",
    "\n",
    "    n_e = 0\n",
    "    for t, (d0, d1) in enumerate(zip(labels, labels[1:])):\n",
    "        r0 = skimage.measure.regionprops(d0)\n",
    "        c0 = [np.array(r.centroid) for r in r0]\n",
    "\n",
    "        r1 = skimage.measure.regionprops(d1)\n",
    "        c1 = [np.array(r.centroid) for r in r1]\n",
    "\n",
    "        for _r0, _c0 in zip(r0, c0):\n",
    "            for _r1, _c1 in zip(r1, c1):\n",
    "                dist = np.linalg.norm(_c0 - _c1)\n",
    "                if _r0.label == _r1.label:\n",
    "                    G.add_edge(\n",
    "                        luts[t][_r0.label],\n",
    "                        luts[t + 1][_r1.label],\n",
    "                        edge_id=n_e,\n",
    "                        is_intertrack_edge=0,\n",
    "                    )\n",
    "                    n_e += 1\n",
    "\n",
    "    if links is not None:\n",
    "        divisions = links[links[:, 3] != 0]\n",
    "        for d in divisions:\n",
    "            if d[1] > 0 and d[1] < labels.shape[0]:\n",
    "                try:\n",
    "                    G.add_edge(\n",
    "                        luts[d[1] - 1][d[3]],\n",
    "                        luts[d[1]][d[0]],\n",
    "                        edge_id=n_e,\n",
    "                        show=\"DIV\",\n",
    "                        is_intertrack_edge=1,\n",
    "                    )\n",
    "                    n_e += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "    trackgraph = motile.TrackGraph(G, frame_attribute=\"time\")\n",
    "\n",
    "    return trackgraph, G\n",
    "\n",
    "\n",
    "def build_graph(detections, max_distance, detection_probs=None, drift=(0, 0)):\n",
    "    \"\"\"Build a candidate graph from a list of detections.\n",
    "\n",
    "     Args:\n",
    "        detections: list of 2D arrays, each array is a label image.\n",
    "            Labels are expected to be consecutive integers starting from 1, background is 0.\n",
    "        max distance: maximum distance between centroids of two detections to place a candidate edge.\n",
    "        detection_probs: list of arrays, corresponding to ordered ids in detections.\n",
    "        drift: (y, x) tuple for drift correction in euclidian distance feature.\n",
    "    Returns:\n",
    "        G: motile.TrackGraph containing the candidate graph.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Build candidate graph\")\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for t, d in enumerate(detections):\n",
    "        regions = skimage.measure.regionprops(d)\n",
    "        positions = []\n",
    "        for i, r in enumerate(regions):\n",
    "            draw_pos = int(d.shape[0] - r.centroid[0])\n",
    "            if draw_pos in positions:\n",
    "                draw_pos += 3  # To avoid overlapping nodes\n",
    "            positions.append(draw_pos)\n",
    "            feature = (\n",
    "                np.round(detection_probs[r.label], decimals=2).item()\n",
    "                if detection_probs is not None\n",
    "                else 1\n",
    "            )\n",
    "            G.add_node(\n",
    "                r.label - 1,\n",
    "                time=t,\n",
    "                show=r.label,\n",
    "                feature=feature,\n",
    "                draw_position=draw_pos,\n",
    "                y=int(r.centroid[0]),\n",
    "                x=int(r.centroid[1]),\n",
    "            )\n",
    "\n",
    "    n_e = 0\n",
    "    for t, (d0, d1) in enumerate(zip(detections, detections[1:])):\n",
    "        r0 = skimage.measure.regionprops(d0)\n",
    "        c0 = [np.array(r.centroid) for r in r0]\n",
    "\n",
    "        r1 = skimage.measure.regionprops(d1)\n",
    "        c1 = [np.array(r.centroid) for r in r1]\n",
    "\n",
    "        for _r0, _c0 in zip(r0, c0):\n",
    "            for _r1, _c1 in zip(r1, c1):\n",
    "                dist = np.linalg.norm(_c0 + np.array(drift) - _c1)\n",
    "                if dist < max_distance:\n",
    "                    G.add_edge(\n",
    "                        _r0.label - 1,\n",
    "                        _r1.label - 1,\n",
    "                        # 1 - normalized euclidian distance\n",
    "                        feature=1\n",
    "                        - np.round(\n",
    "                            np.linalg.norm(_c0 + np.array(drift) - _c1) / max_distance,\n",
    "                            decimals=3,\n",
    "                        ).item(),\n",
    "                        edge_id=n_e,\n",
    "                        show=\"?\",\n",
    "                    )\n",
    "                    n_e += 1\n",
    "\n",
    "    G = motile.TrackGraph(G, frame_attribute=\"time\")\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_graph, gt_nx_graph = build_gt_graph(labels, links.to_numpy())\n",
    "candidate_graph = build_graph(\n",
    "    det, max_distance=50, detection_probs=det_center_probs, drift=(-4, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0e691",
   "metadata": {},
   "source": [
    "Let's visualize the two graphs.\n",
    "\n",
    "In the ground truth graph nodes that belong to the same linear tracklet are marked with the same id. The two divisions in the dataset are marked in yellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_edge_colors = [\n",
    "    (255, 140, 0) if \"show\" in edge else (0, 128, 0) for edge in gt_graph.edges.values()\n",
    "]\n",
    "\n",
    "fig_gt = draw_track_graph(\n",
    "    gt_graph,\n",
    "    position_attribute=\"draw_position\",\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    label_attribute=\"show\",\n",
    "    node_color=(0, 128, 0),\n",
    "    edge_color=gt_edge_colors,\n",
    "    node_size=25,\n",
    ")\n",
    "fig_gt = fig_gt.update_layout(\n",
    "    title={\n",
    "        \"text\": \"Ground truth\",\n",
    "        \"y\": 0.98,\n",
    "        \"x\": 0.5,\n",
    "    }\n",
    ")\n",
    "fig_gt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a920922",
   "metadata": {},
   "source": [
    "You can hover over the nodes and edges of the candidate graph to inspect their features.\n",
    "\n",
    "In contrast to the ground truth graph above, in the candidate graph, nodes have unique IDs.\n",
    "\n",
    "The nodes' `feature` is set to their detection probability, and the edges' `feature` to 1 - normalized_detection_distance, which is also visualized as their color saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476ce86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig_candidate = draw_track_graph(\n",
    "    candidate_graph,\n",
    "    position_attribute=\"draw_position\",\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    label_attribute=\"show\",\n",
    "    alpha_attribute=\"feature\",\n",
    "    node_size=25,\n",
    ")\n",
    "fig_candidate = fig_candidate.update_layout(\n",
    "    title={\n",
    "        \"text\": \"Candidate graph\",\n",
    "        \"y\": 0.98,\n",
    "        \"x\": 0.5,\n",
    "    }\n",
    ")\n",
    "fig_candidate.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918594d",
   "metadata": {},
   "source": [
    "## Network flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25d8360",
   "metadata": {},
   "source": [
    "As hinted earlier, our goal is to prune the candidate graph. More formally we want to find a graph $\\tilde{G}=(\\tilde{V}, \\tilde{E})$ whose vertices $\\tilde{V}$ are a subset of the candidate graph vertices $V$ and whose edges $\\tilde{E}$ are a subset of the candidate graph edges $E$.\n",
    "\n",
    "The first algorithm we will use to do this is a [network flow](https://en.wikipedia.org/wiki/Network_flow_problem). It tries to find as many disjunct paths from the first frame to the last frame as possible. All other vertices and edges are discarded. This specific algorithm is called maximum flow.\n",
    "\n",
    "\n",
    "Finding a good subgraph $\\tilde{G}=(\\tilde{V}, \\tilde{E})$ can be formulated as an [integer linear program (ILP)](https://en.wikipedia.org/wiki/Integer_programming) (also, refer to the tracking lecture slides), where we assign a binary variable $x$ and a cost $c$ to each vertex and edge in $G$, and then computing $min_x c^Tx$.\n",
    "\n",
    "A set of linear constraints ensures that the solution will be a feasible cell tracking graph. For example, if an edge is part of $\\tilde{G}$, both its incident nodes have to be part of $\\tilde{G}$ as well.\n",
    "\n",
    "Here we want to express the network flow as an ILP using `motile` ([docs here](https://funkelab.github.io/motile/)), a convenient wrapper around linking with an ILP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7198d0d0",
   "metadata": {},
   "source": [
    "## Exercise 2.1 - Network flow\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.1: The network flow formulation below needs properly set parameters.</h3>\n",
    "</div>\n",
    "\n",
    "Try different values for `node_weight`, `edge_weight` and `max_flow` and try to get an output similar to the plot right below.\n",
    "\n",
    "Give a short explanation why your parameters work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9a254",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "<img src=\"figures/network_flow.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f4b9cc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Here is a utility function to gauge some statistics of a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa00bff4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def print_solution_stats(solver, graph, gt_graph):\n",
    "    \"\"\"Prints the number of nodes and edges for candidate, ground truth graph, and solution graph.\n",
    "\n",
    "    Args:\n",
    "        solver: motile.Solver, after calling solver.solve()\n",
    "        graph: motile.TrackGraph, candidate graph\n",
    "        gt_graph: motile.TrackGraph, ground truth graph\n",
    "    \"\"\"\n",
    "    time.sleep(0.1)  # to wait for ilpy prints\n",
    "    print(\n",
    "        f\"\\nCandidate graph\\t\\t{len(graph.nodes):3} nodes\\t{len(graph.edges):3} edges\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Ground truth graph\\t{len(gt_graph.nodes):3} nodes\\t{len(gt_graph.edges):3} edges\"\n",
    "    )\n",
    "\n",
    "    node_selected = solver.get_variables(motile.variables.NodeSelected)\n",
    "    edge_selected = solver.get_variables(motile.variables.EdgeSelected)\n",
    "    nodes = 0\n",
    "    for node in candidate_graph.nodes:\n",
    "        if solver.solution[node_selected[node]] > 0.5:\n",
    "            nodes += 1\n",
    "    edges = 0\n",
    "    for u, v in candidate_graph.edges:\n",
    "        if solver.solution[edge_selected[(u, v)]] > 0.5:\n",
    "            edges += 1\n",
    "    print(f\"Solution graph\\t\\t{nodes:3} nodes\\t{edges:3} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6f89d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "This is the actual formulation of the network flow.\n",
    "\n",
    "First we associate costs for each node and weight to be picked, which are a product of `weight` and `attribute`.\n",
    "\n",
    "Then we add a constraint on how many parents and children each node can be connected to in the solution, and some specific constraints for the network flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3696fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_network_flow(graph, node_weight, edge_weight, max_flow):\n",
    "    \"\"\"Set up and solve the network flow problem.\n",
    "\n",
    "    Args:\n",
    "        graph (motile.TrackGraph): The candidate graph.\n",
    "        node_weight (float): The weighting factor of the node selection cost.\n",
    "        edge_weight (float): The weighting factor of the edge selection cost.\n",
    "        max_flow (int): The maximum number of incoming and outgoing edges in the solution.\n",
    "\n",
    "    Returns:\n",
    "        motile.Solver: The solver object, ready to be inspected.\n",
    "    \"\"\"\n",
    "    solver = motile.Solver(graph)\n",
    "\n",
    "    # Add costs\n",
    "    solver.add_costs(\n",
    "        motile.costs.NodeSelection(\n",
    "            weight=node_weight, attribute=\"feature\"\n",
    "        )  # Adapt this weight\n",
    "    )\n",
    "    solver.add_costs(\n",
    "        motile.costs.EdgeSelection(\n",
    "            weight=edge_weight, attribute=\"feature\"\n",
    "        )  # Adapt this weight\n",
    "    )\n",
    "\n",
    "    solver.add_constraints(motile.constraints.MaxParents(max_flow))\n",
    "    solver.add_constraints(motile.constraints.MaxChildren(max_flow))\n",
    "\n",
    "    # Special contraints for network flow\n",
    "    solver.add_constraints(InOutSymmetry())\n",
    "    solver.add_constraints(MinTrackLength(1))\n",
    "\n",
    "    solution = solver.solve()\n",
    "\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### YOUR CODE HERE ###\n",
    "######################\n",
    "\n",
    "# Reminder: The optimization problem *minimizes* the cost of the solution.\n",
    "node_weight = 1  # Adapt this weight\n",
    "edge_weight = 1  # Adapt this weight\n",
    "max_flow = 4  # Adapt this\n",
    "\n",
    "\"\"\"\n",
    "Explanation: ???\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70af93",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "node_weight = -1\n",
    "edge_weight = -1\n",
    "max_flow = 1\n",
    "\n",
    "\"\"\"\n",
    "Explanation: Since the ILP formulation is a minimization problem, the total weight of each node and edge needs to be negative.\n",
    "The cost of each node corresponds to its detection probability, so we can simply mulitply with `node_weight=-1`.\n",
    "The cost of each edge corresponds to 1 - distance between the two nodes, so agai we can simply mulitply with `edge_weight=-1`.\n",
    "\n",
    "Futhermore, each detection (node) should maximally be linked to one other detection in the previous and next frames, so we set `max_flow=1`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691a915",
   "metadata": {},
   "source": [
    "Here we actually run the optimization, and compare the found solution to the ground truth.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><h3>Gurobi license error</h3>\n",
    "Please ignore the warning `Could not create Gurobi backend ...`.\n",
    "\n",
    "\n",
    "Our integer linear program (ILP) tries to use the proprietary solver Gurobi. You probably don't have a license, in which case the ILP will fall back to the open source solver SCIP.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfa0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = solve_network_flow(candidate_graph, node_weight, edge_weight, max_flow)\n",
    "print_solution_stats(flow, candidate_graph, gt_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b08985",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig_gt.show()\n",
    "fig_flow = draw_solution(\n",
    "    candidate_graph,\n",
    "    flow,\n",
    "    position_attribute=\"draw_position\",\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    label_attribute=\"show\",\n",
    "    node_size=25,\n",
    ")\n",
    "fig_flow = fig_flow.update_layout(\n",
    "    title={\n",
    "        \"text\": f\"Network flow (no divisions) - cost: {flow.solution.get_value()}\",\n",
    "        \"y\": 0.98,\n",
    "        \"x\": 0.5,\n",
    "    }\n",
    ")\n",
    "fig_flow.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1949216",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Recolor detections in napari according to solution and compare to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution2graph(solver, base_graph, detections, label_key=\"show\"):\n",
    "    \"\"\"Convert a solver solution to a graph and corresponding dense selected detections.\n",
    "\n",
    "    Args:\n",
    "        solver: A solver instance\n",
    "        base_graph: The base graph\n",
    "        detections: The detections\n",
    "        label_key: The key of the label in the detections\n",
    "    Returns:\n",
    "        track_graph: Solution as motile.TrackGraph\n",
    "        graph: Solution as networkx graph\n",
    "        selected_detections: Dense label array containing only selected detections\n",
    "    \"\"\"\n",
    "    graph = nx.DiGraph()\n",
    "    node_indicators = solver.get_variables(motile.variables.NodeSelected)\n",
    "    edge_indicators = solver.get_variables(motile.variables.EdgeSelected)\n",
    "\n",
    "    selected_detections = np.zeros_like(detections)\n",
    "\n",
    "    # Build nodes\n",
    "    for node, index in node_indicators.items():\n",
    "        if solver.solution[index] > 0.5:\n",
    "            node_features = base_graph.nodes[node]\n",
    "            graph.add_node(node, **node_features)\n",
    "            t = node_features[base_graph.frame_attribute]\n",
    "            selected_detections[t][\n",
    "                detections[t] == node_features[label_key]\n",
    "            ] = node_features[label_key]\n",
    "\n",
    "    # Build edges\n",
    "    for edge, index in edge_indicators.items():\n",
    "        if solver.solution[index] > 0.5:\n",
    "            # print(base_graph.edges[edge])\n",
    "            graph.add_edge(*edge, **base_graph.edges[edge])\n",
    "\n",
    "    # Add cell division markers on edges for traccuracy\n",
    "    for (u, v), features in graph.edges.items():\n",
    "        out_edges = graph.out_edges(u)\n",
    "        if len(out_edges) == 2:\n",
    "            features[\"is_intertrack_edge\"] = 1\n",
    "        elif len(out_edges) == 1:\n",
    "            features[\"is_intertrack_edge\"] = 0\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "    track_graph = motile.TrackGraph(graph, frame_attribute=\"time\")\n",
    "\n",
    "    return track_graph, graph, selected_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b18a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recolor_segmentation(segmentation, graph, det_attribute=\"show\"):\n",
    "    \"\"\"Recolor a segmentation based on a graph, such that each cell and its daughter cells have a unique color.\n",
    "\n",
    "    Args:\n",
    "        segmentation (np.ndarray): Predicted dense segmentation.\n",
    "        graph (motile.TrackGraph): A directed graph representing the tracks.\n",
    "        det_attribute (str): The attribute of the graph nodes that corresponds to ids in `segmentation`.\n",
    "\n",
    "    Returns:\n",
    "        out (np.ndarray): A recolored segmentation.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    n_tracks = 1\n",
    "    color_lookup_tables = []\n",
    "\n",
    "    for t in range(0, len(segmentation)):\n",
    "        new_frame = np.zeros_like(segmentation[t])\n",
    "        color_lut = {}\n",
    "        for node_id in graph.nodes_by_frame(t):\n",
    "            det_id = graph.nodes[node_id][det_attribute]\n",
    "            if node_id not in graph.nodes:\n",
    "                continue\n",
    "\n",
    "            in_edges = []\n",
    "            for u, v in graph.edges:\n",
    "                if v == node_id:\n",
    "                    in_edges.append((u, v))\n",
    "            if not in_edges:\n",
    "                new_frame[segmentation[t] == det_id] = n_tracks\n",
    "                color_lut[det_id] = n_tracks\n",
    "                n_tracks += 1\n",
    "            else:\n",
    "                for v_tm1, u_t0 in in_edges:\n",
    "                    new_frame[\n",
    "                        segmentation[t] == graph.nodes[u_t0][det_attribute]\n",
    "                    ] = color_lookup_tables[t - 1][graph.nodes[v_tm1][det_attribute]]\n",
    "                    color_lut[graph.nodes[u_t0][det_attribute]] = color_lookup_tables[\n",
    "                        t - 1\n",
    "                    ][graph.nodes[v_tm1][det_attribute]]\n",
    "\n",
    "        color_lookup_tables.append(color_lut)\n",
    "        out.append(new_frame)\n",
    "\n",
    "    out = np.stack(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recolored_gt = recolor_segmentation(labels, gt_graph)\n",
    "recolored_flow = recolor_segmentation(\n",
    "    det, graph=solution2graph(flow, candidate_graph, det)[0]\n",
    ")\n",
    "\n",
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img)\n",
    "viewer.add_labels(recolored_gt)\n",
    "viewer.add_labels(recolored_flow)\n",
    "viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7f728",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be275b60",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Metrics\n",
    "\n",
    "We were able to understand via plotting the solution graph as well as visualizing the predicted tracks on the images that the network flow solution is far from perfect for this problem.\n",
    "\n",
    "Additionally, we would also like to quantify this. We will use the package [`traccuracy`](https://traccuracy.readthedocs.io/en/latest/) to calculate some [standard metrics for cell tracking](http://celltrackingchallenge.net/evaluation-methodology/). For example, a high-level indicator for tracking performance is called TRA.\n",
    "\n",
    "If you're interested in more detailed metrics, you can check out for example the false positive (FP) and false negative (FN) nodes, edges and division events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedfe27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(gt_graph, labels, pred_graph, pred_segmentation):\n",
    "    \"\"\"Calculate metrics for linked tracks by comparing to ground truth.\n",
    "\n",
    "    Args:\n",
    "        gt_graph (networkx.DiGraph): Ground truth graph.\n",
    "        labels (np.ndarray): Ground truth detections.\n",
    "        pred_graph (networkx.DiGraph): Predicted graph.\n",
    "        pred_segmentation (np.ndarray): Predicted dense segmentation.\n",
    "\n",
    "    Returns:\n",
    "        results (dict): Dictionary of metric results.\n",
    "    \"\"\"\n",
    "\n",
    "    gt_graph = traccuracy.TrackingGraph(\n",
    "        graph=gt_graph,\n",
    "        frame_key=\"time\",\n",
    "        label_key=\"show\",\n",
    "        location_keys=(\"x\", \"y\"),\n",
    "    )\n",
    "    gt_data = traccuracy.TrackingData(gt_graph, segmentation=labels)\n",
    "\n",
    "    pred_graph = traccuracy.TrackingGraph(\n",
    "        graph=pred_graph,\n",
    "        frame_key=\"time\",\n",
    "        label_key=\"show\",\n",
    "        location_keys=(\"x\", \"y\"),\n",
    "    )\n",
    "    pred_data = traccuracy.TrackingData(pred_graph, segmentation=pred_segmentation)\n",
    "\n",
    "    results = run_metrics(\n",
    "        gt_data=gt_data,\n",
    "        pred_data=pred_data,\n",
    "        matcher=CTCMatched,\n",
    "        metrics=[CTCMetrics, DivisionMetrics],\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed8cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, flow_nx_graph, flow_det = solution2graph(flow, candidate_graph, det)\n",
    "get_metrics(gt_nx_graph, labels, flow_nx_graph, flow_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08275c59",
   "metadata": {},
   "source": [
    "## Checkpoint 1\n",
    "<div class=\"alert alert-block alert-success\"><h3>Checkpoint 1: We have familiarized ourselves with the formulation of linking as a graph-based optimization problem and have an solution found by an efficient network flow formulation.</h3>\n",
    "\n",
    "However, in the video at hand there are cells coming into the field of view from below. To track these, we need change the optimization problem to allow for appearing and disappearing object at any timepoint.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85057b4",
   "metadata": {},
   "source": [
    "## Exercise 2.2 - ILP with track birth and death\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.2: Adapt the network flow from Exercise 2.1 such that tracks can start and end at arbitrary time points.</h3>\n",
    "\n",
    "Hint: You will have to add both costs and constraints to the template below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5cca7f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Expected output:\n",
    "\n",
    "<img src=\"figures/ilp_nodiv.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de2a05",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def solve_ilp_birth(graph):\n",
    "    \"\"\"ILP allowing for appearance and disappearance of cells.\n",
    "\n",
    "    Args:\n",
    "        graph (motile.TrackGraph): The candidate graph.\n",
    "\n",
    "    Returns:\n",
    "        solver (motile.Solver): The solver.\n",
    "    \"\"\"\n",
    "\n",
    "    solver = motile.Solver(graph)\n",
    "\n",
    "    # Add costs\n",
    "    # Docs: https://funkelab.github.io/motile/api.html#costs\n",
    "    ######################\n",
    "    ### YOUR CODE HERE ###\n",
    "    ######################\n",
    "\n",
    "    # Add constraints\n",
    "    # Docs: https://funkelab.github.io/motile/api.html#constraints\n",
    "    ######################\n",
    "    ### YOUR CODE HERE ###\n",
    "    ######################\n",
    "    solver.add_constraints(motile.constraints.MaxChildren(1))\n",
    "\n",
    "    solution = solver.solve()\n",
    "\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e552a",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "\n",
    "def solve_ilp_birth(graph):\n",
    "    \"\"\"ILP allowing for appearance and disappearance of cells.\n",
    "\n",
    "    Args:\n",
    "        graph (motile.TrackGraph): The candidate graph.\n",
    "\n",
    "    Returns:\n",
    "        solver (motile.Solver): The solver.\n",
    "    \"\"\"\n",
    "    solver = motile.Solver(graph)\n",
    "\n",
    "    # Add costs\n",
    "    solver.add_costs(\n",
    "        motile.costs.NodeSelection(\n",
    "            weight=-1,\n",
    "            attribute=\"feature\",\n",
    "        )\n",
    "    )\n",
    "    solver.add_costs(\n",
    "        motile.costs.EdgeSelection(\n",
    "            weight=-1,\n",
    "            attribute=\"feature\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add constraints\n",
    "    solver.add_constraints(motile.constraints.MaxParents(1))\n",
    "    solver.add_constraints(motile.constraints.MaxChildren(1))\n",
    "\n",
    "    solution = solver.solve()\n",
    "\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccb104",
   "metadata": {},
   "source": [
    "Run the optimization, and compare the found solution to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35910cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_birth = solve_ilp_birth(candidate_graph)\n",
    "print_solution_stats(with_birth, candidate_graph, gt_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_gt.show()\n",
    "fig_birth = draw_solution(\n",
    "    candidate_graph,\n",
    "    with_birth,\n",
    "    position_attribute=\"draw_position\",\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    label_attribute=\"show\",\n",
    "    node_size=25,\n",
    ")\n",
    "fig_birth = fig_birth.update_layout(\n",
    "    title={\n",
    "        \"text\": f\"ILP formulation (no divisions) - cost: {with_birth.solution.get_value()}\",\n",
    "        \"y\": 0.98,\n",
    "        \"x\": 0.5,\n",
    "    }\n",
    ")\n",
    "fig_birth.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f07094",
   "metadata": {},
   "outputs": [],
   "source": [
    "recolored_gt = recolor_segmentation(labels, gt_graph)\n",
    "recolored_birth = recolor_segmentation(\n",
    "    det, graph=solution2graph(with_birth, candidate_graph, det)[0]\n",
    ")\n",
    "\n",
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img)\n",
    "viewer.add_labels(recolored_gt)\n",
    "viewer.add_labels(recolored_birth)\n",
    "viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98415dd0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, birth_graph, birth_det = solution2graph(with_birth, candidate_graph, det)\n",
    "get_metrics(gt_nx_graph, labels, birth_graph, birth_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8546ce0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ILP model including divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446abe5b",
   "metadata": {},
   "source": [
    "## Exercise 2.3\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.3: Adapt the ILP formulation to include divisions.</h3>\n",
    "</div>\n",
    "\n",
    "Specifically, adapt one constraint and add costs for `Appear` and `Split` events, refer to [docs](https://funkelab.github.io/motile/api.html#costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95f01c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Expected output: **Capture at least one of the two divisions**.\n",
    "\n",
    "Try to make sure that there are little or no false positive predictions.\n",
    "\n",
    "<img src=\"figures/ilp_div.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3a52f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def solve_full_ilp(graph):\n",
    "    \"\"\"ILP allowing for cell division.\n",
    "\n",
    "    Args:\n",
    "        graph (motile.TrackGraph): The candidate graph.\n",
    "\n",
    "    Returns:\n",
    "        solver (motile.Solver): The solver.\n",
    "    \"\"\"\n",
    "    solver = motile.Solver(graph)\n",
    "\n",
    "    # Add costs\n",
    "    solver.add_costs(motile.costs.NodeSelection(weight=-1, attribute=\"feature\"))\n",
    "    solver.add_costs(motile.costs.EdgeSelection(weight=-1, attribute=\"feature\"))\n",
    "\n",
    "    ######################\n",
    "    ### YOUR CODE HERE ###\n",
    "    ######################\n",
    "\n",
    "    # Add constraints\n",
    "    solver.add_constraints(motile.constraints.MaxParents(1))\n",
    "    solver.add_constraints(motile.constraints.MaxChildren(1))\n",
    "\n",
    "    solution = solver.solve()\n",
    "\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b40b33",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "\n",
    "def solve_full_ilp(graph):\n",
    "    \"\"\"ILP allowing for cell division.\n",
    "\n",
    "    Args:\n",
    "        graph (motile.TrackGraph): The candidate graph.\n",
    "\n",
    "    Returns:\n",
    "        solver (motile.Solver): The solver.\n",
    "    \"\"\"\n",
    "    solver = motile.Solver(graph)\n",
    "\n",
    "    # Add costs\n",
    "    solver.add_costs(motile.costs.NodeSelection(weight=-1, attribute=\"feature\"))\n",
    "    solver.add_costs(motile.costs.EdgeSelection(weight=-1, attribute=\"feature\"))\n",
    "    solver.add_costs(motile.costs.Appear(constant=0.75))\n",
    "    solver.add_costs(motile.costs.Split(constant=1.5))\n",
    "\n",
    "    # Add constraints\n",
    "    solver.add_constraints(motile.constraints.MaxParents(1))\n",
    "    solver.add_constraints(motile.constraints.MaxChildren(2))\n",
    "\n",
    "    solution = solver.solve()\n",
    "\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ilp = solve_full_ilp(candidate_graph)\n",
    "print_solution_stats(full_ilp, candidate_graph, gt_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_gt.show()\n",
    "fig_ilp = draw_solution(\n",
    "    candidate_graph,\n",
    "    full_ilp,\n",
    "    position_attribute=\"draw_position\",\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    label_attribute=\"show\",\n",
    "    node_size=25,\n",
    ")\n",
    "fig_ilp = fig_ilp.update_layout(\n",
    "    title={\n",
    "        \"text\": f\"ILP formulation with divisions - cost: {full_ilp.solution.get_value()}\",\n",
    "        \"y\": 0.98,\n",
    "        \"x\": 0.5,\n",
    "    }\n",
    ")\n",
    "fig_ilp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a5fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recolored_gt = recolor_segmentation(labels, gt_graph)\n",
    "recolored_ilp = recolor_segmentation(\n",
    "    det, graph=solution2graph(full_ilp, candidate_graph, det)[0]\n",
    ")\n",
    "\n",
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img)\n",
    "viewer.add_labels(recolored_gt)\n",
    "viewer.add_labels(recolored_ilp)\n",
    "viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02019057",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ilp_graph, ilp_det = solution2graph(full_ilp, candidate_graph, det)\n",
    "get_metrics(gt_nx_graph, labels, ilp_graph, ilp_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dcd6da",
   "metadata": {},
   "source": [
    "## Exercise 2.4 (Bonus)\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.4: Try to improve the ILP-based tracking from exercise 2.3</h3>\n",
    "\n",
    "For example\n",
    "- Tune the hyperparameters.\n",
    "- Better edge features than drift-corrected euclidian distance.\n",
    "- Tune the detection algorithm to avoid false negatives.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "formats": "py:percent,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
