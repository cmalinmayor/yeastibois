{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9fc14f2",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d98b399-0bce-4a05-b684-ba1f65f4bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e486fafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Notebook at full width in the browser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import napari\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import plotly.io as pio\n",
    "\n",
    "# pio.renderers.default = \"notebook_connected\"\n",
    "pio.renderers.default = \"iframe\"\n",
    "\n",
    "import motile\n",
    "from motile.plot import draw_track_graph, draw_solution\n",
    "# from utils import InOutSymmetry, MinTrackLength\n",
    "\n",
    "import traccuracy\n",
    "from traccuracy import run_metrics\n",
    "from traccuracy.matchers import CTCMatched\n",
    "from traccuracy.metrics import CTCMetrics, DivisionMetrics\n",
    "# from KL_load_data import load_raw_masks\n",
    "\n",
    "from tqdm import tqdm\n",
    "import zarr\n",
    "\n",
    "# Pretty tqdm progress bars\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "320678bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 15/15 [00:09<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# zarrpath = \"/mnt/efs/shared_data/YeastiBois/zarr_files/Tien/glass_60x_023_RawMasks.zarr\"\n",
    "\n",
    "zarrpath = '/mnt/efs/shared_data/YeastiBois/zarr_files/Tien/glass_60x_023_RawMasksProbs.zarr'\n",
    "zarrfile =  zarr.open(zarrpath,'r')\n",
    "mask = zarrfile['masks'] #segmentation mask\n",
    "raw = zarrfile['raw']\n",
    "probs = zarrfile['probs']\n",
    "# unique = np.unique(mask) #number of unique labeles in the segmentation mask\n",
    "# fullmask = mask[:] #load the full mask into memory\n",
    "# nonzero_unique = unique[1:] #zero is empty space\n",
    "\n",
    "raw_MembraneChannel = raw[:,:,0]\n",
    "\n",
    "# mask_frame = mask[0].astype(int)\n",
    "#remove small objects to clean up masks\n",
    "mask_clean = np.stack([skimage.morphology.remove_small_objects(m.astype(int), min_size=1000) for m in tqdm(mask)])\n",
    "\n",
    "# NapariViewer = napari.Viewer()\n",
    "# NapariViewer.add_image(raw_MembraneChannel,name='raw')\n",
    "# NapariViewer.add_labels(mask_clean,name='mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9bafaa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def visualize_tracks(viewer, y, links=None, name=\"\"):\n",
    "    \"\"\"Utility function to visualize segmentation and tracks\n",
    "\n",
    "    Args:\n",
    "        viewer: napari viewer\n",
    "        y: labels: list of 2D arrays, each array is a label image.\n",
    "        links: np.ndarray, each row is a link (parent, child, parent_frame, child_frame).\n",
    "\n",
    "    Returns:\n",
    "        tracks: np.ndarray, shape (N, 4)\n",
    "    \"\"\"\n",
    "    max_label = max(links.max(), y.max()) if links is not None else y.max()\n",
    "    colorperm = np.random.default_rng(42).permutation(np.arange(1, max_label + 2))\n",
    "    tracks = []\n",
    "    for t, frame in enumerate(y):\n",
    "        centers = skimage.measure.regionprops(frame)\n",
    "        for c in centers:\n",
    "            tracks.append(\n",
    "                [colorperm[c.label], t, int(c.centroid[0]), int(c.centroid[1])]\n",
    "            )\n",
    "    tracks = np.array(tracks)\n",
    "    tracks = tracks[tracks[:, 0].argsort()]\n",
    "\n",
    "    graph = {}\n",
    "    if links is not None:\n",
    "        divisions = links[links[:, 3] != 0]\n",
    "        for d in divisions:\n",
    "            if (\n",
    "                colorperm[d[0]] not in tracks[:, 0]\n",
    "                or colorperm[d[3]] not in tracks[:, 0]\n",
    "            ):\n",
    "                continue\n",
    "            graph[colorperm[d[0]]] = [colorperm[d[3]]]\n",
    "\n",
    "    viewer.add_labels(y, name=f\"{name}_detections\")\n",
    "    # viewer.layers[f\"{name}_detections\"].contour = 3\n",
    "    viewer.add_tracks(tracks, name=f\"{name}_tracks\", graph=graph)\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e94dcd9e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# viewer = napari.viewer.current_viewer()\n",
    "# if viewer:\n",
    "#     viewer.close()\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(img)\n",
    "# #visualize_tracks(viewer, labels, links.to_numpy(), \"ground_truth\")\n",
    "# visualize_tracks(viewer, labels)\n",
    "# #viewer.add_labels(det, name=\"detections\")\n",
    "# #viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "314ee1d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a72f087",
   "metadata": {},
   "source": [
    "#### Build the ground truth graph, as well as a candidate graph from the detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45aead91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(detections, max_distance, node_features=None, drift=(0, 0, 0)):\n",
    "    \"\"\"Build a candidate graph from a list of detections.\n",
    "\n",
    "     Args:\n",
    "        detections: list of 2D arrays, each array is a label image.\n",
    "            Labels are expected to be consecutive integers starting from 1, background is 0.\n",
    "        max distance: maximum distance between centroids of two detections to place a candidate edge.\n",
    "        node_features: dict of arrays corresponding to global node ids\n",
    "        drift: (y, x) tuple for drift correction in euclidian distance feature.\n",
    "    Returns:\n",
    "        G: motile.TrackGraph containing the candidate graph.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Build candidate graph\")\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    print(\"add nodes\")\n",
    "    for t, d in tqdm(enumerate(detections)):\n",
    "        regions = skimage.measure.regionprops(d)\n",
    "        positions = []\n",
    "        for i, r in enumerate(regions):\n",
    "            draw_pos = int(r.centroid[1])\n",
    "            if draw_pos in positions:\n",
    "                draw_pos += 3  # To avoid overlapping nodes\n",
    "            positions.append(draw_pos)\n",
    "            \n",
    "            features = {\n",
    "                k: np.round(v[r.label-1], decimals=2).item() if v is not None else 1\n",
    "                for k,v in node_features.items()\n",
    "            }\n",
    "            G.add_node(\n",
    "                r.label-1,\n",
    "                time=t,\n",
    "                show=r.label,\n",
    "                draw_position=draw_pos,\n",
    "                z=int(r.centroid[0]),\n",
    "                y=int(r.centroid[1]),\n",
    "                x=int(r.centroid[2]),\n",
    "                **features,\n",
    "            )\n",
    "\n",
    "    print(\"add edges\")\n",
    "    n_e = 0\n",
    "    for t, (d0, d1) in tqdm(enumerate(zip(detections, detections[1:]))):\n",
    "        r0 = skimage.measure.regionprops(d0)\n",
    "        c0 = [np.array(r.centroid) for r in r0]\n",
    "\n",
    "        r1 = skimage.measure.regionprops(d1)\n",
    "        c1 = [np.array(r.centroid) for r in r1]\n",
    "\n",
    "        for _r0, _c0 in zip(r0, c0):\n",
    "            for _r1, _c1 in zip(r1, c1):\n",
    "                dist = np.linalg.norm(_c0 + np.array(drift) - _c1)\n",
    "                if dist < max_distance:\n",
    "                    G.add_edge(\n",
    "                        _r0.label - 1,\n",
    "                        _r1.label - 1,\n",
    "                        # before: 1 - normalized euclidian distance\n",
    "                        feature=np.round(\n",
    "                            np.linalg.norm(_c0 + np.array(drift) - _c1) / max_distance,\n",
    "                            decimals=3,\n",
    "                        ).item(),\n",
    "                        edge_id=n_e,\n",
    "                        show=\"?\",\n",
    "                    )\n",
    "                    n_e += 1\n",
    "\n",
    "    G = motile.TrackGraph(G, frame_attribute=\"time\")\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "791141cc-b95a-4111-ba0f-46e0672c7923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▌                                                          | 3/15 [00:03<00:15,  1.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     frame, _, _ \u001b[38;5;241m=\u001b[39m skimage\u001b[38;5;241m.\u001b[39msegmentation\u001b[38;5;241m.\u001b[39mrelabel_sequential(frame, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m frame\n\u001b[0;32m----> 9\u001b[0m     offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m     relabeled\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[1;32m     12\u001b[0m labels_global \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(relabeled)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/conda/envs/08-ilp-tracking/lib/python3.9/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/08-ilp-tracking/lib/python3.9/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#ids are unique over the course of the video, cellpose relabeled from 1 every timestep\n",
    "#global IDs\n",
    "\n",
    "offset = 1\n",
    "relabeled = []\n",
    "for frame in tqdm(mask_clean):\n",
    "    frame, _, _ = skimage.segmentation.relabel_sequential(frame, offset=offset)\n",
    "    assert 0 in frame\n",
    "    offset += len(np.unique(frame)) - 1\n",
    "    relabeled.append(frame)\n",
    "\n",
    "labels_global = np.stack(relabeled)\n",
    "print(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c900101-e91c-4cbc-b0eb-4fa3a265306e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1117"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_global.shape\n",
    "labels_global.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa543ca0-0bfd-4ed2-a152-1126bd57a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  7.33it/s]\n",
      "15it [00:24,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "#create node feature\n",
    "#det_probs = normalized size of regions\n",
    "det_probs = []\n",
    "for frame in tqdm(labels_global):\n",
    "    regions = skimage.measure.regionprops(frame)\n",
    "    for r in regions:\n",
    "        det_probs.append(r.num_pixels)\n",
    "det_probs = np.array(det_probs) / np.array(det_probs).max() #normalize by max\n",
    "\n",
    "#Probs = probabilities\n",
    "avg_probs = []\n",
    "for _l, _p in tqdm(zip(labels_global, probs)):\n",
    "    assert _p.min() >= 0 and _p.max() <= 1\n",
    "    indices = np.unique(_l)\n",
    "    for i in indices:\n",
    "        if i == 0:\n",
    "            continue\n",
    "        a = _p[_l == i].mean()\n",
    "        avg_probs.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b95e042-58fd-4c03-8bfe-2657c1fe2d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build candidate graph\n",
      "add nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:08,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:06,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# graph for how many frames\n",
    "s = slice(0, 10)#10 frames\n",
    "labels_crop = labels_global[s]\n",
    "img_crop = raw_MembraneChannel[s]\n",
    "candidate_graph = build_graph(\n",
    "    labels_crop,\n",
    "    max_distance=100,\n",
    "    node_features={\n",
    "        \"size\": det_probs,\n",
    "        \"avg_prob\": avg_probs,\n",
    "    },\n",
    "    drift=(0,0,0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3778822-99d9-4273-9e0a-ee5111052822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8476ce86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1020px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_19.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show candidate graphs\n",
    "\n",
    "fig_candidate = draw_track_graph(\n",
    "    candidate_graph,\n",
    "    position_attribute=\"draw_position\",\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    label_attribute=\"show\",\n",
    "    alpha_attribute=\"feature\",\n",
    "    node_size=25,\n",
    ")\n",
    "fig_candidate = fig_candidate.update_layout(\n",
    "    title={\n",
    "        \"text\": \"Candidate graph\",\n",
    "        \"y\": 0.98,\n",
    "        \"x\": 0.5,\n",
    "    }\n",
    ")\n",
    "fig_candidate.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f4b9cc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Here is a utility function to gauge some statistics of a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa00bff4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def print_solution_stats(solver, graph, gt_graph=None):\n",
    "    \"\"\"Prints the number of nodes and edges for candidate, ground truth graph, and solution graph.\n",
    "\n",
    "    Args:\n",
    "        solver: motile.Solver, after calling solver.solve()\n",
    "        graph: motile.TrackGraph, candidate graph\n",
    "        gt_graph: motile.TrackGraph, ground truth graph\n",
    "    \"\"\"\n",
    "    time.sleep(0.1)  # to wait for ilpy prints\n",
    "    print(\n",
    "        f\"\\nCandidate graph\\t\\t{len(graph.nodes):3} nodes\\t{len(graph.edges):3} edges\"\n",
    "    )\n",
    "    if gt_graph:\n",
    "        print(\n",
    "            f\"Ground truth graph\\t{len(gt_graph.nodes):3} nodes\\t{len(gt_graph.edges):3} edges\"\n",
    "        )\n",
    "\n",
    "    node_selected = solver.get_variables(motile.variables.NodeSelected)\n",
    "    edge_selected = solver.get_variables(motile.variables.EdgeSelected)\n",
    "    nodes = 0\n",
    "    for node in candidate_graph.nodes:\n",
    "        if solver.solution[node_selected[node]] > 0.5:\n",
    "            nodes += 1\n",
    "    edges = 0\n",
    "    for u, v in candidate_graph.edges:\n",
    "        if solver.solution[edge_selected[(u, v)]] > 0.5:\n",
    "            edges += 1\n",
    "    print(f\"Solution graph\\t\\t{nodes:3} nodes\\t{edges:3} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1949216",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Recolor detections in napari according to solution and compare to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "426b395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution2graph(solver, base_graph, detections, label_key=\"show\"):\n",
    "    \"\"\"Convert a solver solution to a graph and corresponding dense selected detections.\n",
    "\n",
    "    Args:\n",
    "        solver: A solver instance\n",
    "        base_graph: The base graph\n",
    "        detections: The detections\n",
    "        label_key: The key of the label in the detections\n",
    "    Returns:\n",
    "        track_graph: Solution as motile.TrackGraph\n",
    "        graph: Solution as networkx graph\n",
    "        selected_detections: Dense label array containing only selected detections\n",
    "    \"\"\"\n",
    "    graph = nx.DiGraph()\n",
    "    node_indicators = solver.get_variables(motile.variables.NodeSelected)\n",
    "    edge_indicators = solver.get_variables(motile.variables.EdgeSelected)\n",
    "\n",
    "    selected_detections = np.zeros_like(detections)\n",
    "\n",
    "    # Build nodes\n",
    "    for node, index in node_indicators.items():\n",
    "        if solver.solution[index] > 0.5:\n",
    "            node_features = base_graph.nodes[node]\n",
    "            graph.add_node(node, **node_features)\n",
    "            t = node_features[base_graph.frame_attribute]\n",
    "            selected_detections[t][\n",
    "                detections[t] == node_features[label_key]\n",
    "            ] = node_features[label_key]\n",
    "\n",
    "    # Build edges\n",
    "    for edge, index in edge_indicators.items():\n",
    "        if solver.solution[index] > 0.5:\n",
    "            # print(base_graph.edges[edge])\n",
    "            graph.add_edge(*edge, **base_graph.edges[edge])\n",
    "\n",
    "    # Add cell division markers on edges for traccuracy\n",
    "    for (u, v), features in graph.edges.items():\n",
    "        out_edges = graph.out_edges(u)\n",
    "        if len(out_edges) == 2:\n",
    "            features[\"is_intertrack_edge\"] = 1\n",
    "        elif len(out_edges) == 1:\n",
    "            features[\"is_intertrack_edge\"] = 0\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "    track_graph = motile.TrackGraph(graph, frame_attribute=\"time\")\n",
    "\n",
    "    return track_graph, graph, selected_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49b18a95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def recolor_segmentation(segmentation, graph, det_attribute=\"show\"):\n",
    "    \"\"\"Recolor a segmentation based on a graph, such that each cell and its daughter cells have a unique color.\n",
    "\n",
    "    Args:\n",
    "        segmentation (np.ndarray): Predicted dense segmentation.\n",
    "        graph (motile.TrackGraph): A directed graph representing the tracks.\n",
    "        det_attribute (str): The attribute of the graph nodes that corresponds to ids in `segmentation`.\n",
    "\n",
    "    Returns:\n",
    "        out (np.ndarray): A recolored segmentation.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    n_tracks = 1\n",
    "    color_lookup_tables = []\n",
    "\n",
    "    for t in range(0, len(segmentation)):\n",
    "        new_frame = np.zeros_like(segmentation[t])\n",
    "        color_lut = {}\n",
    "        for node_id in graph.nodes_by_frame(t):\n",
    "            det_id = graph.nodes[node_id][det_attribute]\n",
    "            if node_id not in graph.nodes:\n",
    "                continue\n",
    "\n",
    "            in_edges = []\n",
    "            for u, v in graph.edges:\n",
    "                if v == node_id:\n",
    "                    in_edges.append((u, v))\n",
    "            if not in_edges:\n",
    "                new_frame[segmentation[t] == det_id] = n_tracks\n",
    "                color_lut[det_id] = n_tracks\n",
    "                n_tracks += 1\n",
    "            else:\n",
    "                for v_tm1, u_t0 in in_edges:\n",
    "                    new_frame[\n",
    "                        segmentation[t] == graph.nodes[u_t0][det_attribute]\n",
    "                    ] = color_lookup_tables[t - 1][graph.nodes[v_tm1][det_attribute]]\n",
    "                    color_lut[graph.nodes[u_t0][det_attribute]] = color_lookup_tables[\n",
    "                        t - 1\n",
    "                    ][graph.nodes[v_tm1][det_attribute]]\n",
    "\n",
    "        color_lookup_tables.append(color_lut)\n",
    "        out.append(new_frame)\n",
    "\n",
    "    out = np.stack(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85057b4",
   "metadata": {},
   "source": [
    "## Exercise 2.2 - ILP with track birth and death\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.2: Adapt the network flow from Exercise 2.1 such that tracks can start and end at arbitrary time points.</h3>\n",
    "\n",
    "Hint: You will have to add both costs and constraints to the template below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8de2a05",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def solve(graph):\n",
    "    \"\"\"ILP allowing for appearance and disappearance of cells.\n",
    "\n",
    "    Args:\n",
    "        graph (motile.TrackGraph): The candidate graph.\n",
    "\n",
    "    Returns:\n",
    "        solver (motile.Solver): The solver.\n",
    "    \"\"\"\n",
    "\n",
    "    solver = motile.Solver(graph)\n",
    "\n",
    "    solver.add_costs(\n",
    "        motile.costs.NodeSelection(\n",
    "            weight=-1,\n",
    "            attribute=\"size\",\n",
    "            constant=0,\n",
    "        ),\n",
    "        name=\"size\",\n",
    "    )\n",
    "    solver.add_costs(\n",
    "        motile.costs.NodeSelection(\n",
    "            weight=-1,\n",
    "            attribute=\"avg_prob\",\n",
    "            constant=0,\n",
    "        ),\n",
    "        name=\"avg_prob\",\n",
    "    )\n",
    "    # weight * attribute + constant\n",
    "    solver.add_costs(\n",
    "        motile.costs.EdgeSelection(\n",
    "            weight = 0.01,#+0.5 or 1...\n",
    "            attribute=\"feature\",\n",
    "            constant=0,\n",
    "        )\n",
    "    )\n",
    "    solver.add_costs(motile.costs.Appear(constant=0.5))\n",
    "    # solver.add_costs(motile.costs.Split(constant=1))\n",
    "    solver.add_costs(motile.costs.Disappear(constant=0.5))\n",
    "    \n",
    "    solver.add_constraints(motile.constraints.MaxParents(1))\n",
    "    solver.add_constraints(motile.constraints.MaxChildren(1))\n",
    "\n",
    "    solution = solver.solve()\n",
    "\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccb104",
   "metadata": {},
   "source": [
    "Run the optimization, and compare the found solution to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35910cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not create Gurobi backend: Gurobi error in ilpy/impl/solvers/GurobiBackend.cpp:22: PIP license can only be used from gurobipy interface\n",
      "\n",
      "Candidate graph\t\t702 nodes\t2712 edges\n",
      "Solution graph\t\t620 nodes\t498 edges\n"
     ]
    }
   ],
   "source": [
    "with_birth = solve(candidate_graph)\n",
    "print_solution_stats(with_birth, candidate_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1924ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_birth = draw_solution(\n",
    "#     candidate_graph,\n",
    "#     with_birth,\n",
    "#     position_attribute=\"draw_position\",\n",
    "#     width=1000,\n",
    "#     height=500,\n",
    "#     label_attribute=\"show\",\n",
    "#     node_size=25,\n",
    "# )\n",
    "# fig_birth = fig_birth.update_layout(\n",
    "#     title={\n",
    "#         \"text\": f\"ILP formulation (no divisions) - cost: {with_birth.solution.get_value()}\",\n",
    "#         \"y\": 0.98,\n",
    "#         \"x\": 0.5,\n",
    "#     }\n",
    "# )\n",
    "# fig_birth.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48f07094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Qt: Session management error: None of the authentication protocols specified are supported\n"
     ]
    }
   ],
   "source": [
    "recolored_birth = recolor_segmentation(\n",
    "    labels_crop, graph=solution2graph(with_birth, candidate_graph, labels_crop)[0]\n",
    ")\n",
    "\n",
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img_crop)\n",
    "viewer.add_labels(labels_crop)\n",
    "# visualize_track\n",
    "# visualize_tracks(viewer, recolored_birth)\n",
    "\n",
    "viewer.add_labels(recolored_birth)\n",
    "viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "110cf3fc-c982-434e-a0a2-d759ac9c3fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#save tracks\n",
    "\n",
    "# imgdata = img_crop\n",
    "# labeldata = labels_crop\n",
    "# savepath = '/home/tienc/Documents/trackvids/tracked.zarr/'\n",
    "# with zarr.open(savepath,'w') as zarrsave:\n",
    "#     zarrsave.create_dataset('img',data=imgdata)\n",
    "#     zarrsave.create_dataset('label',data=labeldata)\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98415dd0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, birth_graph, birth_det = solution2graph(with_birth, candidate_graph, det)\n",
    "get_metrics(gt_nx_graph, labels, birth_graph, birth_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02019057",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ilp_graph, ilp_det = solution2graph(full_ilp, candidate_graph, det)\n",
    "get_metrics(gt_nx_graph, labels, ilp_graph, ilp_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dcd6da",
   "metadata": {},
   "source": [
    "## Exercise 2.4 (Bonus)\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.4: Try to improve the ILP-based tracking from exercise 2.3</h3>\n",
    "\n",
    "For example\n",
    "- Tune the hyperparameters.\n",
    "- Better edge features than drift-corrected euclidian distance.\n",
    "- Tune the detection algorithm to avoid false negatives.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "formats": "py:percent,ipynb"
  },
  "kernelspec": {
   "display_name": "Python [conda env:08-ilp-tracking]",
   "language": "python",
   "name": "conda-env-08-ilp-tracking-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
